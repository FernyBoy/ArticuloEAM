@article{gonzalez2024clasificador,
  title = {Clasificador de Bosquejos Utilizando Memoria Asociativa Entr\'opica Pesada.},
  author = {{Gonz\'alez-Hern\'andez}, Julian Rodrigo and {Figueroa-Mora}, Karina Mariela and Pineda, Luis A and {Morales-Gamboa}, Rafael},
  year = {2024},
  journal = {Research in Computing Science},
  volume = {153},
  number = {7},
  pages = {217--227},
  issn = {1870-4069},
  file = {/home/rmorales/Zotero/storage/KNWHTM45/González-Hernández et al. - 2024 - Clasificador de bosquejos utilizando memoria asociativa entrópica pesada..pdf}
}

@misc{googlecreativelabQuickDrawData2025,
  title = {Quick, {{Draw}}! {{The Data}}},
  author = {Google Creative Lab},
  year = {2025},
  month = mar,
  journal = {Quick, Draw!},
  urldate = {2025-09-16},
  abstract = {What would you do with 50,000,000 drawings made by real people on the internet?},
  howpublished = {https://quickdraw.withgoogle.com/data},
  langid = {english}
}

@article{moralesMissingCueProblem2025,
  title = {The Missing Cue Problem in Hetero Associative Memory Retrieval},
  author = {Morales, Rafael and Pineda, Luis A.},
  year = {2025},
  month = jul,
  journal = {Scientific Reports},
  volume = {15},
  number = {1},
  pages = {21850},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-025-07963-x},
  urldate = {2025-08-21},
  abstract = {The Entropic Associative Memory is an auto-associative memory in which objects are represented and stored as discrete functions or ``traces'' in a table, so the memory content is a 2D relation or ``memory plane''. Memory traces are ``overlapped'' on the medium, the memory is indeterminate, and the system is entropic. The memory retrieval operation produces an object out of a cue and the indeterminate memory mass, and the memory is constructive. In this paper, we present its extension to the hetero-associative case. Pairs of hetero-associated objects, possibly of different domain and/or modalities, are held in a 4D relation. The cue to a memory retrieval operation selects a largely indeterminate 2D hetero-associated memory plane, but there is no cue left to recover the object from such plane. We propose three incremental methods to address such missing cue problem, which we call random, sample and test, and search and test. The model is assessed with composite recollections consisting of manuscript digits and letters selected from the MNIST and EMNIST corpora, respectively, such that cue digits retrieve their associated letters and vice versa. We show the memory performance and illustrate the memory retrieval operation using all three methods. The system shows promise for storing, recognizing, and retrieving very large sets of objects with very limited computing resources. We also discuss the implications of the model for the psychology and the neuroscience of memory.},
  copyright = {2025 The Author(s)},
  langid = {english},
  keywords = {Computer science,Long-term memory,Psychology},
  file = {/home/rmorales/Zotero/storage/FYTF797V/Morales and Pineda - 2025 - The missing cue problem in hetero associative memory retrieval.pdf}
}

@article{pinedaImageryEntropicAssociative2023,
  title = {Imagery in the Entropic Associative Memory},
  author = {Pineda, Luis A. and Morales, Rafael},
  year = {2023},
  month = jun,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {9553},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-36761-6},
  urldate = {2023-08-10},
  abstract = {The Entropic Associative Memory is a novel declarative and distributed computational model of associative memory. The model is general, conceptually simple, and offers an alternative to models developed within the artificial neural networks paradigm. The memory uses a standard table as its medium, where the information is stored in an indeterminate form, and the entropy plays a functional and operation role. The memory register operation abstracts the input cue with the current memory content and is productive; memory recognition is performed through a logical test; and memory retrieval is constructive. The three operations can be performed in parallel using very few computing resources. In our previous work we explored the auto-associative properties of the memory and performed experiments to store, recognize and retrieve manuscript digits and letters with complete and incomplete cues, and also to recognize and learn phones, with satisfactory results. In such experiments a designated memory register was used to store all the objects of the same class, whereas in the present study we remove such restriction and use a single memory register to store all the objects in the domain. In this novel setting we explore the production of emerging objects and relations, such that cues are used not only to retrieve remembered objects, but also related and imaged objects, and to produce association chains. The present model supports the view that memory and classification are independent functions both conceptually and architecturally. The memory system can store images of the different modalities of perception and action, possibly multimodal, and offers a novel perspective on the imagery debate and computational models of declarative memory.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Mathematics and computing,Psychology},
  file = {/home/rmorales/Zotero/storage/5U7WFJ46/Pineda_Morales_2023_Imagery in the entropic associative memory.pdf}
}

@article{scheirerOpenSetRecognition2013,
  title = {Toward {{Open Set Recognition}}},
  author = {Scheirer, Walter J. and {de Rezende Rocha}, Anderson and Sapkota, Archana and Boult, Terrance E.},
  year = {2013},
  month = jul,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {35},
  number = {7},
  pages = {1757--1772},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2012.256},
  urldate = {2025-09-16},
  abstract = {To date, almost all experimental evaluations of machine learning-based recognition algorithms in computer vision have taken the form of ``closed set'' recognition, whereby all testing classes are known at training time. A more realistic scenario for vision applications is ``open set'' recognition, where incomplete knowledge of the world is present at training time, and unknown classes can be submitted to an algorithm during testing. This paper explores the nature of open set recognition and formalizes its definition as a constrained minimization problem. The open set recognition problem is not well addressed by existing algorithms because it requires strong generalization. As a step toward a solution, we introduce a novel ``1-vs-set machine,'' which sculpts a decision space from the marginal distances of a 1-class or binary SVM with a linear kernel. This methodology applies to several different applications in computer vision where open set recognition is a challenging problem, including object recognition and face verification. We consider both in this work, with large scale cross-dataset experiments performed over the Caltech 256 and ImageNet sets, as well as face matching experiments performed over the Labeled Faces in the Wild set. The experiments highlight the effectiveness of machines adapted for open set evaluation compared to existing 1-class and binary SVMs for the same tasks.},
  keywords = {1-vs-set machine,Face,Face recognition,face verification,machine learning,object recognition,Object recognition,Open set recognition,support vector machines,Support vector machines,Testing,Training,Training data}
}

@misc{zalandoresearchFashionMNIST2022,
  title = {Fashion-{{MNIST}}},
  author = {Zalando Research},
  year = {2022},
  month = nov,
  urldate = {2022-11-04},
  abstract = {A MNIST-like fashion product database. Benchmark :point_down:},
  copyright = {MIT},
  keywords = {benchmark,computer-vision,convolutional-neural-networks,dataset,deep-learning,fashion,fashion-mnist,gan,machine-learning,mnist,zalando}
}

@book{russell2020artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2020},
  publisher={Pearson}
}