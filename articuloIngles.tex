\documentclass[conference]{IEEEtran} % puedes cambiar a article si prefieres

%% IEEE Trans parece requerir el uso de PDFLaTeX
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{float}
\usepackage{booktabs}
\usepackage[spanish]{babel}

\title{Validación a gran escala y Análisis de la Capacidad de Rechazo en la Memoria Asociativa Entrópica}

\author{
    Angel Fernando Bórquez Guerrero \\
    Rafael Morales Gamboa \\
}

\begin{document}

\maketitle

% -------------------- Abstract --------------------
\begin{abstract}
The Entropic Associative Memory (EAM), proposed by Pineda and Morales (2023), is a computational model inspired by human cognition that combines probabilistic recognition properties with an efficient architecture for pattern storage and retrieval. In previous studies, EAM was evaluated using the Fashion MNIST dataset, yielding positive results in image classification and reconstruction, although limited to a reduced domain of only ten classes.

This work presents two main contributions aimed at overcoming these limitations. First, we assess the scalability of the model by migrating to a substantially larger dataset: Google’s \emph{Quick, Draw!}, which contains more than 300 classes and hundreds of thousands of examples per category. Second, we design a rejection experiment to verify whether the memory is capable of identifying and not recognizing those classes that were not explicitly stored. To this end, the memory is trained with only half of the classes and evaluated on the complete set.

The results confirm that EAM can adapt to more complex scenarios and suggest that it may provide an effective rejection mechanism against novel stimuli, offering evidence of its potential as an explainable and robust model within the field of artificial intelligence.
\end{abstract}




% -------------------- Keywords --------------------
\begin{IEEEkeywords}
Entropic Associative Memory, Quick Draw, Fashion MNIST, scalability, open-set recognition
\end{IEEEkeywords}



% -------------------- Introducción --------------------
\section{Introduction}

\noindent The development of memory models inspired by human cognition has become a rapidly growing research area within artificial intelligence (AI) [REFS]. These approaches aim to computationally reproduce the ability of biological systems to store, associate, and retrieve information from past experiences. In this context, the \textit{Entropic Associative Memory} (EAM), proposed by Pineda and Morales \cite{pinedaImageryEntropicAssociative2023}, represents a significant theoretical advancement by providing a declarative, distributed, and efficient architecture capable of probabilistic recognition and flexible pattern retrieval.

Initial studies with EAM focused on classical and relatively small datasets such as \textit{Fashion MNIST} \cite{zalandoresearchFashionMNIST2022}, which contains 70,000 images across 10 object classes. In this domain, the model demonstrated the ability to store latent representations generated by a convolutional autoencoder and to retrieve these representations even in the presence of noise or incomplete information. These results validated the effectiveness of the model in closed-set recognition tasks, where all test classes (though not all instances) had been previously stored in memory.

However, the original experimental framework presented three main limitations. First, the evaluation was carried out in a small and limited domain, restricting the analysis of the model’s scalability. Second, the memory’s ability to explicitly reject instances from non-stored classes had not been tested, a critical aspect in \emph{open-set recognition} problems \cite{scheirerOpenSetRecognition2013}.

This work seeks to overcome these limitations through two lines of research: (1) evaluating the scalability of EAM using the \textit{Quick, Draw!} dataset \cite{googlecreativelabQuickDrawData2025}, which contains more than 300 classes and hundreds of thousands of examples per category; and (2) designing a rejection experiment to examine the memory’s performance in not recognizing non-stored classes.

In this way, the article contributes to broadening the understanding of the behavior of the Entropic Associative Memory in more complex scenarios, providing empirical evidence of its robustness, generalization capacity, and potential as an alternative paradigm within explainable artificial intelligence.



% -------------------- Antecedentes --------------------
\section{Background}

\noindent The \textit{Entropic Associative Memory} (EAM), proposed by Pineda and Morales \cite{pinedaImageryEntropicAssociative2023}, emerges as a computational model inspired by human cognition, designed to probabilistically and distributively store and retrieve patterns. Unlike conventional memory systems, EAM operates on a single \textit{Associative Memory Register}, which concentrates the associations of all learned patterns in a matrix representation. This approach enables flexible behavior in recognition and retrieval and opens the door to the study of emergent phenomena such as generalization and synthetic image generation.

The model is based on three main operations: 
\begin{itemize}
    \item \textbf{$\lambda$-register}: records a pattern in memory by reinforcing associations among its features.
    \item \textbf{$\eta$-recognition}: determines whether an input stimulus is recognized by the memory, using error tolerance criteria and confidence thresholds.
    \item \textbf{$\beta$-retrieval}: retrieves a complete pattern from a cue, which may be partial or noisy, by leveraging probabilistic distributions over the stored associations.
\end{itemize}
%
In previous experiments, EAM was evaluated with the \textit{Fashion MNIST} dataset \cite{zalandoresearchFashionMNIST2022}, which consists of 70,000 images across 10 classes. In this setting, the memory was supplied with latent representations generated by a convolutional autoencoder and demonstrated the ability to both recognize and reconstruct patterns even under noisy or incomplete conditions. Furthermore, emergent phenomena such as the generation of memory sequences (\textit{association chains}) were explored, showing the system’s capacity to transition between stored representations. A subsequent study was carried out using Google’s \emph{Quick, Draw!} dataset, with small variations in the number of classes (between 10 and 13), yielding acceptable results \cite{gonzalez2024clasificador}.

Despite these promising results, the original experimental framework presented relevant limitations:  
(1) the evaluation was restricted to a reduced set of 10 classes, which hindered the analysis of model scalability in more complex contexts;  
(2) no systematic tests were conducted on the memory’s ability to reject patterns from unseen classes, a fundamental aspect in open-set recognition; and  
(3) the experimental design was tightly coupled to the fixed number of classes configured in the neural networks, limiting flexibility in exploring different memory-loading configurations.

These limitations motivate the present work, whose goal is to validate EAM in a more challenging environment through migration to the \textit{Quick, Draw!} dataset \cite{googlecreativelabQuickDrawData2025} and the design of a specific experiment to analyze its rejection capability against unseen classes.



% -------------------- Metodología --------------------
\section{Methodology}

\noindent To extend the validation of the Entropic Associative Memory (EAM) model and analyze its behavior in more complex scenarios, an experimental methodology was designed and divided into three main phases. These phases enabled migration to a new data domain, evaluation of the explicit rejection mechanism, and provided the system with greater flexibility for future experiments.

\subsection{Dataset Migration and Large-Scale Validation}
\noindent The first step consisted of replacing the \textit{Fashion MNIST} dataset with \textit{Quick, Draw!} \cite{googlecreativelabQuickDrawData2025}, which contains more than 300 classes and hundreds of thousands of examples per category. This process required:
\begin{itemize}
    \item \textbf{Adaptation of the data module:} The \texttt{dataset.py} script was modified to load, process, and dynamically balance \emph{Quick, Draw!} classes. The logic was adjusted to handle a variable number of categories and to guarantee an equal number of samples per class.
    \item \textbf{Retraining of neural networks:} The perceptual system, consisting of an autoencoder and a classifier (defined in \texttt{neural\_net.py}), was adjusted based on the work in \cite{moralesMissingCueProblem2025} and retrained from scratch using \emph{Quick, Draw!} as the new data source. This step produced suitable latent representations (\textit{features}) for the memory.
    \item \textbf{Pipeline validation:} The full workflow (autoencoder-classifier training, feature generation, memory storage, and recognition evaluation) was executed to verify the model’s compatibility with the new domain.
\end{itemize}

\subsection{Design and Implementation of the Rejection Experiment}
\noindent To analyze the system’s ability to reject patterns from unseen classes, a second experiment was implemented with the following logic:
\begin{itemize}
    \item \textbf{Extension of the command interface:} A new argument was added to the main program \texttt{eam.py} (\texttt{-e 2}) to invoke this experimental mode.
    \item \textbf{Partial memory registration:} Although the classifier was trained with all selected classes, only half of them were stored in EAM.
    \item \textbf{Evaluation with the complete set:} During the test phase, the system was exposed to all classes, including those not stored, enabling explicit evaluation of its rejection response.
    \item \textbf{Acceptance and rejection metric:} The \texttt{no\_response} index was employed as a quantitative measure to evaluate the system’s ability to avoid associating patterns from unseen classes.
\end{itemize}

\subsection{Refactoring for Experimental Flexibility}
\noindent To transform the system into a more versatile experimental platform, additional modifications were carried out:
\begin{itemize}
    \item \textbf{Parameterization of the number of classes:} The \texttt{eam.py} program was modified to accept the number of classes as a runtime argument (\texttt{<classes>}), instead of being hardcoded.
    \item \textbf{Parameter propagation:} This value was passed to the data module, allowing dynamic preparation of only the required subset of classes.
    \item \textbf{Dynamic loading:} The system was enabled to run experiments with different numbers of classes (2, 4, 8, 16, 24, or 32), adapting to controlled scenarios of varying complexity.
\end{itemize}
%
Taken together, these three methodological phases allowed the model to scale to a substantially larger domain, analyze its rejection capability when facing novel stimuli, and provide a more flexible infrastructure for future experimental trials.



% -------------------- Resultados --------------------
\section{Resultados}

\subsection{Resultados cuantitativos por número de clases}
\indent En esta sección se presenta el desempeño del autoencodificador-clasificador y la memoria asociativa entrópica al variar el número de clases. De las 345 clases que contiene el conjunto de datos \emph{Quick, Draw!} se seleccionaron 64 en total, se revolvieron aleatoriamente y del conjunto resultante se fueron tomando las primeras 2, 4, 8, 16, 24 y 32 clases. El conjunto de datos resultante en cada caso se dividió en tres: el corpus de entrenamiento del autocodificador-clasificador, el corpus de llenado de la memoria asociativa entrópica y el corpus de prueba de ambos. Por cuestiones de tiempo y limitaciones en la cantidad de memoria del servidor, no se hicieron pruebas con más clases y solamente se ejecutó una sola validación por número de clases, en vez de la validación cruzada. Sin embargo, la coherencia de los resultados sugiere que estos no están lejos de lo que se obtendría con una validación cruzada.

Como en \cite{pinedaImageryEntropicAssociative2023} y \cite{moralesMissingCueProblem2025}, las redes neuronales que implementan el autocodificador y el clasificador fueron entrenadas conjuntamente. El Cuadro~\ref{tab:autoencoder-classifier-performance} presenta su desempeño en el conjunto de prueba para las distintas cantidades de clases tomadas del conjunto de datos. Como se puede observar, el desempeño del clasificador tiende a bajar conforme aumenta el número de clases, pero se mantuvo arriba del 91\% de exactitud. El desempeño del autocodificador se mantiene un poco más estable, con una diferencia menor al 3\% entre todos los casos.

\begin{table}[htbp]
	\centering
	\caption{Desempeño del autocodificador (raíz cuadrada del error promedio) y el clasificador (exactitud) para distintas cantidades de clases.}
	\begin{tabular}{@{}ccc@{}}\toprule
		No. de clases & Exactitud &  Error \\
		\midrule
		2 & 0.976 & 0.218 \\
		4 & 0.950 & 0.215 \\
		8 & 0.921 & 0.204 \\
		16 & 0.914 & 0.218 \\
		24	& 0.917 & 0.228 \\
		32 & 0.917 & 0.229 \\
		\bottomrule
	\end{tabular}
	\label{tab:autoencoder-classifier-performance}
\end{table}

\subsection{Resultados del experimento de reconocimiento (todas las clases registradas en memoria)}
\noindent En este experimento la memoria almacenó todas las clases disponibles, con las que las redes neuronales fueron entrenadas y evaluadas. Las figuras de la \ref{fig:precision_2} a la \ref{fig:precision_32} muestran los desempeños correspondientes de la memoria asociativa entrópica usando las métricas de precisión y exactitud. En todos los casos se mantuvo el mismo número de columnas en la memoria (256) y se varió el número de renglones en potencias de dos, desde 2 hasta 1024. De manera general, se puede observar que los desempeños con 4 o más renglones fueron muy similares entre sí y similares a los obtenidos por el clasificador.

% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 2 clases.}
    \label{fig:precision_2}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 4 clases.}
    \label{fig:precision_4}
\end{figure}

% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 8 clases.}
    \label{fig:precision_8}
\end{figure}

% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 16 clases.}
    \label{fig:precision_16}
\end{figure}

% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 24 clases.}
    \label{fig:precision_24}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 32 clases.}
    \label{fig:precision_32}
\end{figure}


% --------------------
\noindent Para observar el desempeño de la memoria conforme se va llenando de recuerdos, para cada cantidad de clases se selecciono un número de renglones con buen desempeño y se observó el comportamiento de la precisión y la exactitud de la memoria conforme se fue llenando en porcentajes que también variaron en potencias de dos. Las figuras de la \ref{fig:recall_exp1_2_004} a la \ref{fig:recall_exp1_32_016} presentan los resultados obtenidos. En general, se puede decir que el desempeño de la memoria se mantiene cuando se llena con al menos el 8\% del corpus de llenado.


% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/recall-exp_001-sze_004-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 2 clases y memoria con 4 renglones.}
    \label{fig:recall_exp1_2_004}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 4 clases y memoria con 32 renglones.}
    \label{fig:recall_exp1_4_032}
\end{figure}


% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 8 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_8_016}
\end{figure}


% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 16 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_16_016}
\end{figure}


% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/recall-exp_001-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 24 clases y memoria con 32 renglones.}
    \label{fig:recall_exp1_24_032}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 32 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_32_016}
\end{figure}


% --------------------


\subsection{Resultados del experimento de rechazo de clases no registradas}
\noindent En este experimento solamente se registró en la memoria la primera mitad de las clases, pero se evaluó contra el conjunto completo. Para cada cantidad de clases se seleccionó el mismo número de renglones para la memoria que en el experimento anterior (figuras de la \ref{fig:recall_exp1_2_004} a la \ref{fig:recall_exp1_32_016}) y se observó el desempeño de la memoria conforme se fue llenando. Las figuras de la \ref{fig:recall_exp2_2_004} a la \ref{fig:recall_exp2_32_016} presentan las gráficas de precisión y exactitud correspondientes. Se puede observar como el desempeño de la memoria comienza muy bien con dos clases y poca información registrada en ella, y va disminuyendo conforme se incrementan tanto el número de clases como la cantidad de elementos del corpus de llenado que se registra en la memoria.

% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/recall-exp_002-sze_004-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 2 clases y memoria con 4 renglones.}
    \label{fig:recall_exp2_2_004}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/recall-exp_002-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 4 clases y memoria con 32 renglones.}
    \label{fig:recall_exp2_4_032}
\end{figure}


% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 8 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_8_016}
\end{figure}


% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 16 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_16_016}
\end{figure}


% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/recall-exp_002-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 24 clases y memoria con 32 renglones.}
    \label{fig:recall_exp2_24_032}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 32 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_32_016}
\end{figure}



% -------------------- Discución --------------------
\section{Discusión}

Los resultados experimentales permiten extraer varias observaciones relevantes sobre el comportamiento de la Memoria Asociativa Entrópica (EAM) en escenarios de mayor complejidad.

En primer lugar, al aumentar progresivamente el número de clases (2, 4, 8, 16, 24 y 32), se observó una tendencia general a la disminución en las métricas de precisión y recall. Este comportamiento es esperado, ya que la complejidad del dominio y la variabilidad de los patrones crece con el número de categorías. No obstante, la EAM mantuvo un desempeño estable en configuraciones de baja y media complejidad, lo que confirma su capacidad para escalar más allá del dominio reducido de Fashion MNIST.

En segundo lugar, los experimentos de rechazo evidenciaron que la memoria fue capaz de identificar patrones correspondientes a clases registradas en ella y rechazar las instancias de las clases no registradas. Este resultado constituye una validación empírica de la hipótesis de que la EAM puede operar en escenarios de reconocimiento abierto, diferenciando entre estímulos familiares y no familiares. Sin embargo, también se detectaron casos de falsas aceptaciones en clases no registradas conforme aumentó el número de clases o el porcentaje del corpus de llenado registrado en la memoria, lo que sugiere la necesidad de ajustar parámetros de umbral ($\iota$ y $\kappa$ \cite{pinedaImageryEntropicAssociative2023,moralesMissingCueProblem2025}), probar otros números de renglones o explorar mecanismos complementarios de discriminación.

Finalmente, la comparación con el clasificador base resalta el papel de la memoria en el sistema completo. Mientras que el clasificador aporta representaciones latentes útiles, es la EAM la que confiere la capacidad de rechazo y recuperación probabilística, aportando un valor añadido frente a arquitecturas puramente discriminativas.

En conjunto, estos hallazgos demuestran que la EAM no solo puede adaptarse a dominios más complejos, sino que también ofrece un mecanismo efectivo para tratar con información novedosa. Al mismo tiempo, ponen de manifiesto retos futuros relacionados con la optimización de sus parámetros y la evaluación en dominios aún más grandes y heterogéneos.



% -------------------- Conclusiones --------------------
\section{Conclusiones}

Este trabajo amplió el marco experimental de la Memoria Asociativa Entrópica (EAM) para evaluar su desempeño en escenarios de mayor complejidad y analizar su capacidad de rechazo ante clases no registradas. Las principales contribuciones pueden resumirse de la siguiente manera:

\begin{itemize}
    \item \textbf{Validación a gran escala:} Se migró de un dominio reducido de diez clases en Fashion MNIST a un dominio más amplio y diverso utilizando \emph{Quick, Draw!}, con resultados que confirman la capacidad del modelo para escalar en contextos con cientos de clases y mayor variabilidad en los patrones.
    
    \item \textbf{Capacidad de rechazo:} Se diseñó e implementó un nuevo experimento que mostró empíricamente cómo la EAM es capaz de emitir una respuesta de \texttt{no\_response} frente a estímulos correspondientes a clases no vistas, validando su utilidad en problemas de reconocimiento abierto.
    
    \item \textbf{Flexibilidad experimental:} El sistema fue refactorizado para aceptar un número variable de clases y distintos tamaños de memoria, lo que habilita un entorno más versátil para la exploración de configuraciones y análisis comparativos.
\end{itemize}

Los hallazgos obtenidos demuestran que la EAM constituye un modelo explicable y robusto, capaz de combinar el almacenamiento distribuido con mecanismos probabilísticos de recuperación y rechazo. Estos resultados refuerzan su potencial como paradigma alternativo dentro de la inteligencia artificial, particularmente en tareas donde la capacidad de manejar información novedosa resulta crítica.

Como trabajo futuro, se propone extender los experimentos hacia dominios aún más grandes y heterogéneos, optimizar los parámetros de umbral asociados al rechazo, e investigar la integración de la EAM con arquitecturas de aprendizaje profundo más avanzadas para fortalecer tanto su precisión como su capacidad de generalización.



% -------------------- Referencias --------------------
\bibliographystyle{IEEEtran}
\bibliography{articulo}
\end{document}
