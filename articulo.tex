\documentclass[conference]{IEEEtran} % puedes cambiar a article si prefieres

%% IEEE Trans parece requerir el uso de PDFLaTeX
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{float}
\usepackage{booktabs}
\usepackage[spanish]{babel}

\title{Validación a gran escala y Análisis de la Capacidad de Rechazo en la Memoria Asociativa Entrópica}

\author{
    Angel Fernando Bórquez Guerrero \\
    Rafael Morales Gamboa \\
}

\begin{document}

\maketitle

% -------------------- Abstract --------------------
\begin{abstract}
La Memoria Asociativa Entrópica (EAM), propuesta por Pineda y Morales (2023), constituye un modelo computacional inspirado en la cognición humana que combina propiedades de reconocimiento probabilístico con una arquitectura eficiente de almacenamiento y recuperación de patrones. En estudios previos, la EAM fue evaluada utilizando el conjunto de datos Fashion MNIST, obteniendo resultados positivos en la clasificación y reconstrucción de imágenes, aunque con la limitación de operar en un dominio reducido de solo diez clases. 

En este trabajo se presentan dos contribuciones principales orientadas a superar estas limitaciones. En primer lugar, se evalúa la escalabilidad del modelo al migrar a un conjunto de datos sustancialmente mayor: \emph{Quick, Draw!} de Google, con más de 300 clases y cientos de miles de ejemplos por categoría. En segundo lugar, se diseña un experimento de rechazo que permite verificar si la memoria es capaz de identificar y no reconocer aquellas clases que no fueron almacenadas explícitamente. Para ello, la memoria se entrena con solo la mitad de las clases y se evalúa sobre el conjunto completo. 

Los resultados obtenidos confirman que la EAM puede adaptarse a escenarios de mayor complejidad y sugieren que puede ofrecer un mecanismo efectivo de rechazo frente a estímulos inéditos, aportando evidencia de su potencial como modelo explicable y robusto dentro del campo de la inteligencia artificial.
\end{abstract}



% -------------------- Keywords --------------------
\begin{IEEEkeywords}
Memoria Asociativa Entrópica, Quick Draw, Fashion MNIST, escalabilidad, open-set recognition
\end{IEEEkeywords}



% -------------------- Introducción --------------------
\section{Introducción}

\noindent El desarrollo de modelos de memoria inspirados en la cognición humana constituye un área de investigación en creciente expansión dentro de la inteligencia artificial (IA) [REFS]. Estos enfoques buscan reproducir de manera computacional la capacidad de los sistemas biológicos para almacenar, asociar y recuperar información a partir de experiencias previas. En este contexto, la \textit{Memoria Asociativa Entrópica} (EAM, por sus siglas en inglés) propuesta por Pineda y Morales \cite{pinedaImageryEntropicAssociative2023} representa un avance teórico significativo al ofrecer una arquitectura declarativa, distribuida y eficiente, capaz de realizar reconocimiento probabilístico y recuperación flexible de patrones.

Los estudios iniciales con la EAM se enfocaron en conjuntos de datos clásicos y relativamente pequeños como \textit{Fashion MNIST} \cite{zalandoresearchFashionMNIST2022}, un conjunto con 70,000 imágenes distribuidas en 10 clases de objetos. En este dominio, el modelo demostró ser capaz de almacenar representaciones latentes generadas por un autoencoder convolucional y de recuperar dichas representaciones incluso en presencia de ruido o información incompleta. Estos resultados validaron la eficacia del modelo en tareas de reconocimiento cerrado, donde todas las clases de prueba (no así las instancias) habían sido registradas en memoria.

Sin embargo, el marco experimental original presentaba tres limitaciones principales. En primer lugar, la evaluación se realizó en un dominio pequeño y limitado, lo cual restringía el análisis de escalabilidad del modelo. En segundo lugar, no se había probado de manera explícita la capacidad de la memoria para rechazar instancias de clases no registradas, un aspecto crítico en problemas de \emph{open-set recognition} \cite{scheirerOpenSetRecognition2013}.

El presente trabajo busca superar estas limitaciones a través de dos líneas de investigación: (1) evaluar la escalabilidad de la EAM utilizando el conjunto de datos \textit{Quick, Draw!} \cite{googlecreativelabQuickDrawData2025}, con más de 300 clases y cientos de miles de ejemplos por categoría; (2) diseñar un experimento de rechazo que permita observar el desempeño de la memoria en no reconocer clases no almacenadas.

De esta manera, el artículo contribuye a ampliar la comprensión del comportamiento de la Memoria Asociativa Entrópica en escenarios más complejos, aportando evidencia empírica sobre su robustez, su capacidad de generalización y su potencial como paradigma alternativo dentro de la inteligencia artificial explicable.



% -------------------- Antecedentes --------------------
\section{Antecedentes}

\noindent La \textit{Memoria Asociativa Entrópica} (EAM, por sus siglas en inglés), propuesta por Pineda y Morales \cite{pinedaImageryEntropicAssociative2023}, surge como un modelo computacional inspirado en la cognición humana cuyo propósito es almacenar y recuperar patrones de manera probabilística y distribuida. A diferencia de los sistemas de memoria convencionales, la EAM opera sobre un único registro asociativo (\textit{Associative Memory Register}) que concentra las asociaciones de todos los patrones aprendidos en una representación matricial. Este enfoque permite un comportamiento flexible en el reconocimiento y la recuperación, y abre la puerta al estudio de fenómenos emergentes como la generalización y la generación de imágenes sintéticas.

El modelo se fundamenta en tres operaciones principales: 
\begin{itemize}
    \item \textbf{$\lambda$-register}: registra un patrón en la memoria reforzando las asociaciones entre sus características.
    \item \textbf{$\eta$-recognition}: determina si un estímulo de entrada es reconocido por la memoria, utilizando un criterio de tolerancia a errores y umbrales de confianza.
    \item \textbf{$\beta$-retrieval}: recupera un patrón completo a partir de una pista, que puede ser parcial o con ruido, utilizando distribuciones probabilísticas sobre las asociaciones almacenadas.
\end{itemize}
%
En experimentos previos, la EAM fue evaluada con el conjunto de datos \textit{Fashion MNIST} \cite{zalandoresearchFashionMNIST2022}, compuesto por 70,000 imágenes distribuidas en 10 clases. En este escenario, la memoria fue alimentada con representaciones latentes producidas por un autoencoder convolucional, y demostró capacidad tanto para reconocer como para reconstruir patrones aún en condiciones de ruido o información incompleta. Asimismo, se exploraron fenómenos emergentes como la generación de secuencias de recuerdos (\textit{association chains}), mostrando la capacidad del sistema para transitar entre representaciones almacenadas. Posteriormente, se realizó un primer estudio utilizando el conjunto de datos \emph{Quick, Draw!} de Google, con pequeñas variaciones en el número de clases (entre 10 y 13), con resultados aceptables \cite{gonzalez2024clasificador}.

A pesar de estos resultados prometedores, el marco experimental original presentaba limitaciones relevantes: 
(1) la evaluación se restringió a un conjunto reducido de 10 clases, lo que dificultaba analizar la escalabilidad del modelo en contextos más complejos; 
(2) no se realizaron pruebas sistemáticas sobre la capacidad de la memoria para rechazar patrones de clases no vistas, un aspecto fundamental en el reconocimiento de conjuntos abiertos; y 
(3) el diseño experimental estaba acoplado al número fijo de clases configuradas en las redes neuronales, limitando la flexibilidad para explorar diferentes configuraciones de carga de memoria.

Estas limitaciones motivan el presente trabajo, cuyo objetivo es validar la EAM en un entorno más desafiante mediante la migración al conjunto de datos \textit{Quick, Draw!} \cite{googlecreativelabQuickDrawData2025} y el diseño de un experimento específico para analizar su capacidad de rechazo frente a clases inéditas.



% -------------------- Metodología --------------------
\section{Metodología}

\noindent Con el objetivo de extender la validación del modelo de Memoria Asociativa Entrópica (EAM) y analizar su comportamiento en escenarios más complejos, se diseñó una metodología experimental dividida en tres fases principales. Estas fases permitieron migrar a un nuevo dominio de datos, evaluar el mecanismo de rechazo explícito y dotar al sistema de mayor flexibilidad para futuros experimentos.

\subsection{Migración del conjunto de datos y validación a gran escala}
\noindent El primer paso consistió en reemplazar el conjunto de datos \textit{Fashion MNIST} por \textit{Quick. Draw!} \cite{googlecreativelabQuickDrawData2025}, con más de 300 clases y cientos de miles de ejemplos por categoría. Este proceso requirió:
\begin{itemize}
    \item \textbf{Adaptación del módulo de datos:} Se modificó el script \texttt{dataset.py} para cargar, procesar y balancear dinámicamente clases de \emph{Quick, Draw!}. La lógica se ajustó para manejar un número variable de categorías y garantizar un número equitativo de muestras por clase.
    \item \textbf{Reentrenamiento de las redes neuronales:} Se ajustó el sistema perceptivo, consistente en un autocodificador y un clasificador (definido en \texttt{neural\_net.py}), con base en el trabajo realizado para \cite{moralesMissingCueProblem2025} y se entrenó desde cero el sistema perceptivo  utilizando \emph{Quick, Draw!} como nueva fuente de datos. Este paso generó representaciones latentes (\textit{features}) adecuadas para la memoria.
    \item \textbf{Validación del \emph{pipeline}:} Se ejecutó el flujo completo (entrenamiento del autoencodificador-clasificador, generación de características, almacenamiento en memoria y evaluación de reconocimiento) para verificar la compatibilidad del modelo con el nuevo dominio.
\end{itemize}

\subsection{Diseño e implementación del experimento de rechazo}
\noindent Para analizar la capacidad del sistema de rechazar patrones de clases no vistas, se implementó un segundo experimento con la siguiente lógica:
\begin{itemize}
    \item \textbf{Extensión de la interfaz de comandos:} Se añadió un nuevo argumento en el programa principal \texttt{eam.py} (\texttt{-e 2}) para invocar este modo experimental.
    \item \textbf{Registro parcial en memoria:} Aunque el clasificador fue entrenado con todas las clases seleccionadas, en la EAM se registró únicamente la mitad de ellas.
    \item \textbf{Evaluación con conjunto completo:} En la fase de prueba, el sistema se expuso a todas las clases, incluyendo las no registradas, lo que permitió evaluar explícitamente su respuesta de rechazo.
    \item \textbf{Métrica de aceptación y rechazo:} Se empleó el índice \texttt{no\_response} como medida cuantitativa para evaluar la capacidad del sistema de no asociar patrones pertenecientes a clases no vistas.
\end{itemize}

\subsection{Refactorización para la flexibilidad experimental}
\noindent Con el fin de transformar el sistema en una plataforma experimental más versátil, se llevaron a cabo modificaciones adicionales:
\begin{itemize}
    \item \textbf{Parametrización del número de clases:} El programa \texttt{eam.py} fue modificado para aceptar el número de clases como argumento de ejecución (\texttt{<classes>}), en lugar de estar fijado en el código.
    \item \textbf{Propagación de parámetros:} Este valor fue transmitido al módulo de datos, lo que permitió preparar dinámicamente sólo el subconjunto de clases requerido.
    \item \textbf{Carga dinámica:} El sistema quedó habilitado para realizar experimentos con diferentes cantidades de clases (2, 4, 8, 16, 24 o 32), adaptándose a escenarios controlados de diversa complejidad.
\end{itemize}
%
En conjunto, estas tres fases metodológicas permitieron escalar el modelo hacia un dominio sustancialmente mayor, analizar su capacidad de rechazo ante estímulos inéditos y habilitar una infraestructura más flexible para futuras pruebas experimentales.



% -------------------- Resultados --------------------

\section{Resultados}

\subsection{Resultados cuantitativos por número de clases}
\indent En esta sección se presenta el desempeño del autoencodificador-clasificador y la memoria asociativa entrópica al variar el número de clases. De las 345 clases que contiene el conjunto de datos \emph{Quick, Draw!} se seleccionaron 64 en total, se revolvieron aleatoriamente y del conjunto resultante se fueron tomando las primeras 2, 4, 8, 16, 24 y 32 clases. El conjunto de datos resultante en cada caso se dividió en tres: el corpus de entrenamiento del autocodificador-clasificador, el corpus de llenado de la memoria asociativa entrópica y el corpus de prueba de ambos. Por cuestiones de tiempo y limitaciones en la cantidad de memoria del servidor, no se hicieron pruebas con más clases y solamente se ejecutó una sola validación por número de clases, en vez de la validación cruzada. Sin embargo, la coherencia de los resultados sugiere que estos no están lejos de lo que se obtendría con una validación cruzada.

Como en \cite{pinedaImageryEntropicAssociative2023} y \cite{moralesMissingCueProblem2025}, las redes neuronales que implementan el autocodificador y el clasificador fueron entrenadas conjuntamente. El Cuadro~\ref{tab:autoencoder-classifier-performance} presenta su desempeño en el conjunto de prueba para las distintas cantidades de clases tomadas del conjunto de datos. Como se puede observar, el desempeño del clasificador tiende a bajar conforme aumenta el número de clases, pero se mantuvo arriba del 91\% de exactitud. El desempeño del autocodificador se mantiene un poco más estable, con una diferencia menor al 3\% entre todos los casos.

\begin{table}[htbp]
	\centering
	\caption{Desempeño del autocodificador (raíz cuadrada del error promedio) y el clasificador (exactitud) para distintas cantidades de clases.}
	\begin{tabular}{@{}ccc@{}}\toprule
		No. de clases & Exactitud &  Error \\
		\midrule
		2 & 0.976 & 0.218 \\
		4 & 0.950 & 0.215 \\
		8 & 0.921 & 0.204 \\
		16 & 0.914 & 0.218 \\
		24	& 0.917 & 0.228 \\
		32 & 0.917 & 0.229 \\
		\bottomrule
	\end{tabular}
	\label{tab:autoencoder-classifier-performance}
\end{table}

\subsection{Resultados del experimento de reconocimiento (todas las clases registradas en memoria)}
\noindent En este experimento la memoria almacenó todas las clases disponibles, con las que las redes neuronales fueron entrenadas y evaluadas. Las figuras de la \ref{fig:precision_2} a la \ref{fig:precision_32} muestran los desempeños correspondientes de la memoria asociativa entrópica usando las métricas de precisión y exactitud. En todos los casos se mantuvo el mismo número de columnas en la memoria (256) y se varió el número de renglones en potencias de dos, desde 2 hasta 1024. De manera general, se puede observar que los desempeños con 4 o más renglones fueron muy similares entre sí y similares a los obtenidos por el clasificador.

% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 2 clases.}
    \label{fig:precision_2}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 4 clases.}
    \label{fig:precision_4}
\end{figure}

% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 8 clases.}
    \label{fig:precision_8}
\end{figure}

% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 16 clases.}
    \label{fig:precision_16}
\end{figure}

% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 24 clases.}
    \label{fig:precision_24}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 32 clases.}
    \label{fig:precision_32}
\end{figure}


% --------------------
\noindent Para observar el desempeño de la memoria conforme se va llenando de recuerdos, para cada cantidad de clases se selecciono un número de renglones con buen desempeño y se observó el comportamiento de la precisión y la exactitud de la memoria conforme se fue llenando en porcentajes que también variaron en potencias de dos. Las figuras de la \ref{fig:recall_exp1_2_004} a la \ref{fig:recall_exp1_32_016} presentan los resultados obtenidos. En general, se puede decir que el desempeño de la memoria se mantiene cuando se llena con al menos el 8\% del corpus de llenado.


% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/recall-exp_001-sze_004-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 2 clases y memoria con 4 renglones.}
    \label{fig:recall_exp1_2_004}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 4 clases y memoria con 32 renglones.}
    \label{fig:recall_exp1_4_032}
\end{figure}


% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 8 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_8_016}
\end{figure}


% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 16 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_16_016}
\end{figure}


% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/recall-exp_001-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 24 clases y memoria con 32 renglones.}
    \label{fig:recall_exp1_24_032}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 32 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_32_016}
\end{figure}


% --------------------


\subsection{Resultados del experimento de rechazo de clases no registradas}
\noindent En este experimento solamente se registró en la memoria la primera mitad de las clases, pero se evaluó contra el conjunto completo. Para cada cantidad de clases se seleccionó el mismo número de renglones para la memoria que en el experimento anterior (figuras de la \ref{fig:recall_exp1_2_004} a la \ref{fig:recall_exp1_32_016}) y se observó el desempeño de la memoria conforme se fue llenando. Las figuras de la \ref{fig:recall_exp2_2_004} a la \ref{fig:recall_exp2_32_016} presentan las gráficas de precisión y exactitud correspondientes. Se puede observar como el desempeño de la memoria comienza muy bien con dos clases y poca información registrada en ella, y va disminuyendo conforme se incrementan tanto el número de clases como la cantidad de elementos del corpus de llenado que se registra en la memoria.

% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/recall-exp_002-sze_004-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 2 clases y memoria con 4 renglones.}
    \label{fig:recall_exp2_2_004}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/recall-exp_002-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 4 clases y memoria con 32 renglones.}
    \label{fig:recall_exp2_4_032}
\end{figure}


% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 8 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_8_016}
\end{figure}


% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 16 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_16_016}
\end{figure}


% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/recall-exp_002-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 24 clases y memoria con 32 renglones.}
    \label{fig:recall_exp2_24_032}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 32 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_32_016}
\end{figure}



% -------------------- Discución --------------------
\section{Discusión}

Los resultados experimentales permiten extraer varias observaciones relevantes sobre el comportamiento de la Memoria Asociativa Entrópica (EAM) en escenarios de mayor complejidad.

En primer lugar, al aumentar progresivamente el número de clases (2, 4, 8, 16, 24 y 32), se observó una tendencia general a la disminución en las métricas de precisión y recall. Este comportamiento es esperado, ya que la complejidad del dominio y la variabilidad de los patrones crece con el número de categorías. No obstante, la EAM mantuvo un desempeño estable en configuraciones de baja y media complejidad, lo que confirma su capacidad para escalar más allá del dominio reducido de Fashion MNIST.

En segundo lugar, los experimentos de rechazo evidenciaron que la memoria fue capaz de identificar patrones correspondientes a clases registradas en ella y rechazar las instancias de las clases no registradas. Este resultado constituye una validación empírica de la hipótesis de que la EAM puede operar en escenarios de reconocimiento abierto, diferenciando entre estímulos familiares y no familiares. Sin embargo, también se detectaron casos de falsas aceptaciones en clases no registradas conforme aumentó el número de clases o el porcentaje del corpus de llenado registrado en la memoria, lo que sugiere la necesidad de ajustar parámetros de umbral ($\iota$ y $\kappa$ \cite{pinedaImageryEntropicAssociative2023,moralesMissingCueProblem2025}), probar otros números de renglones o explorar mecanismos complementarios de discriminación.

Finalmente, la comparación con el clasificador base resalta el papel de la memoria en el sistema completo. Mientras que el clasificador aporta representaciones latentes útiles, es la EAM la que confiere la capacidad de rechazo y recuperación probabilística, aportando un valor añadido frente a arquitecturas puramente discriminativas.

En conjunto, estos hallazgos demuestran que la EAM no solo puede adaptarse a dominios más complejos, sino que también ofrece un mecanismo efectivo para tratar con información novedosa. Al mismo tiempo, ponen de manifiesto retos futuros relacionados con la optimización de sus parámetros y la evaluación en dominios aún más grandes y heterogéneos.



% -------------------- Conclusiones --------------------
\section{Conclusiones}

Este trabajo amplió el marco experimental de la Memoria Asociativa Entrópica (EAM) para evaluar su desempeño en escenarios de mayor complejidad y analizar su capacidad de rechazo ante clases no registradas. Las principales contribuciones pueden resumirse de la siguiente manera:

\begin{itemize}
    \item \textbf{Validación a gran escala:} Se migró de un dominio reducido de diez clases en Fashion MNIST a un dominio más amplio y diverso utilizando \emph{Quick, Draw!}, con resultados que confirman la capacidad del modelo para escalar en contextos con cientos de clases y mayor variabilidad en los patrones.
    
    \item \textbf{Capacidad de rechazo:} Se diseñó e implementó un nuevo experimento que mostró empíricamente cómo la EAM es capaz de emitir una respuesta de \texttt{no\_response} frente a estímulos correspondientes a clases no vistas, validando su utilidad en problemas de reconocimiento abierto.
    
    \item \textbf{Flexibilidad experimental:} El sistema fue refactorizado para aceptar un número variable de clases y distintos tamaños de memoria, lo que habilita un entorno más versátil para la exploración de configuraciones y análisis comparativos.
\end{itemize}

Los hallazgos obtenidos demuestran que la EAM constituye un modelo explicable y robusto, capaz de combinar el almacenamiento distribuido con mecanismos probabilísticos de recuperación y rechazo. Estos resultados refuerzan su potencial como paradigma alternativo dentro de la inteligencia artificial, particularmente en tareas donde la capacidad de manejar información novedosa resulta crítica.

Como trabajo futuro, se propone extender los experimentos hacia dominios aún más grandes y heterogéneos, optimizar los parámetros de umbral asociados al rechazo, e investigar la integración de la EAM con arquitecturas de aprendizaje profundo más avanzadas para fortalecer tanto su precisión como su capacidad de generalización.



% -------------------- Referencias --------------------
\bibliographystyle{IEEEtran}
\bibliography{articulo}
\end{document}
