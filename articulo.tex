\documentclass[conference]{IEEEtran} % puedes cambiar a article si prefieres

%% IEEE Trans parece requerir el uso de PDFLaTeX
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{float}
\usepackage{booktabs}

\title{Validación a gran escala y Análisis de la Capacidad de Rechazo en la Memoria Asociativa Entrópica}

\author{
    Angel Fernando Bórquez Guerrero \\
    Rafael Morales Gamboa \\
}

\begin{document}

\maketitle

% -------------------- Abstract --------------------
\begin{abstract}
La Memoria Asociativa Entrópica (EAM), propuesta por Pineda y Morales (2023), constituye un modelo computacional inspirado en la cognición humana que combina propiedades de reconocimiento probabilístico con una arquitectura eficiente de almacenamiento y recuperación de patrones. En estudios previos, la EAM fue evaluada utilizando el conjunto de datos Fashion MNIST, obteniendo resultados positivos en la clasificación y reconstrucción de imágenes, aunque con la limitación de operar en un dominio reducido de solo diez clases. 

En este trabajo se presentan dos contribuciones principales orientadas a superar estas limitaciones. En primer lugar, se evalúa la escalabilidad del modelo al migrar a un conjunto de datos sustancialmente mayor: \emph{Quick, Draw!} de Google, con más de 300 clases y cientos de miles de ejemplos por categoría. En segundo lugar, se diseña un experimento de rechazo que permite verificar si la memoria es capaz de identificar y no reconocer aquellas clases que no fueron almacenadas explícitamente. Para ello, la memoria se entrena con solo la mitad de las clases y se evalúa sobre el conjunto completo. 

Los resultados obtenidos confirman que la EAM puede adaptarse a escenarios de mayor complejidad y sugieren que puede ofrecer un mecanismo efectivo de rechazo frente a estímulos inéditos, aportando evidencia de su potencial como modelo explicable y robusto dentro del campo de la inteligencia artificial.
\end{abstract}



% -------------------- Keywords --------------------
\begin{IEEEkeywords}
Memoria Asociativa Entrópica, Quick Draw, Fashion MNIST, escalabilidad, open-set recognition
\end{IEEEkeywords}



% -------------------- Introducción --------------------
\section{Introducción}

\noindent El desarrollo de modelos de memoria inspirados en la cognición humana constituye un área de investigación en creciente expansión dentro de la inteligencia artificial (IA) [REFS]. Estos enfoques buscan reproducir de manera computacional la capacidad de los sistemas biológicos para almacenar, asociar y recuperar información a partir de experiencias previas. En este contexto, la \textit{Memoria Asociativa Entrópica} (EAM, por sus siglas en inglés) propuesta por Pineda y Morales \cite{pinedaImageryEntropicAssociative2023} representa un avance teórico significativo al ofrecer una arquitectura declarativa, distribuida y eficiente, capaz de realizar reconocimiento probabilístico y recuperación flexible de patrones.

Los estudios iniciales con la EAM se enfocaron en conjuntos de datos clásicos y relativamente pequeños como \textit{Fashion MNIST} \cite{zalandoresearchFashionMNIST2022}, un conjunto con 70,000 imágenes distribuidas en 10 clases de objetos. En este dominio, el modelo demostró ser capaz de almacenar representaciones latentes generadas por un autoencoder convolucional y de recuperar dichas representaciones incluso en presencia de ruido o información incompleta. Estos resultados validaron la eficacia del modelo en tareas de reconocimiento cerrado, donde todas las clases de prueba (no así las instancias) habían sido registradas en memoria.

Sin embargo, el marco experimental original presentaba tres limitaciones principales. En primer lugar, la evaluación se realizó en un dominio pequeño y limitado, lo cual restringía el análisis de escalabilidad del modelo. En segundo lugar, no se había probado de manera explícita la capacidad de la memoria para rechazar instancias de clases no registradas, un aspecto crítico en problemas de \emph{open-set recognition} \cite{scheirerOpenSetRecognition2013}.

El presente trabajo busca superar estas limitaciones a través de dos líneas de investigación: (1) evaluar la escalabilidad de la EAM utilizando el conjunto de datos \textit{Quick, Draw!} \cite{googlecreativelabQuickDrawData2025}, con más de 300 clases y cientos de miles de ejemplos por categoría; (2) diseñar un experimento de rechazo que permita observar el desempeño de la memoria en no reconocer clases no almacenadas.

De esta manera, el artículo contribuye a ampliar la comprensión del comportamiento de la Memoria Asociativa Entrópica en escenarios más complejos, aportando evidencia empírica sobre su robustez, su capacidad de generalización y su potencial como paradigma alternativo dentro de la inteligencia artificial explicable.



% -------------------- Antecedentes --------------------
\section{Antecedentes}

\noindent La \textit{Memoria Asociativa Entrópica} (EAM, por sus siglas en inglés), propuesta por Pineda y Morales \cite{pinedaImageryEntropicAssociative2023}, surge como un modelo computacional inspirado en la cognición humana cuyo propósito es almacenar y recuperar patrones de manera probabilística y distribuida. A diferencia de los sistemas de memoria convencionales, la EAM opera sobre un único registro asociativo (\textit{Associative Memory Register}) que concentra las asociaciones de todos los patrones aprendidos en una representación matricial. Este enfoque permite un comportamiento flexible en el reconocimiento y la recuperación, y abre la puerta al estudio de fenómenos emergentes como la generalización y la generación de imágenes sintéticas.

El modelo se fundamenta en tres operaciones principales: 
\begin{itemize}
    \item \textbf{$\lambda$-register}: registra un patrón en la memoria reforzando las asociaciones entre sus características.
    \item \textbf{$\eta$-recognition}: determina si un estímulo de entrada es reconocido por la memoria, utilizando un criterio de tolerancia a errores y umbrales de confianza.
    \item \textbf{$\beta$-retrieval}: recupera un patrón completo a partir de una pista, que puede ser parcial o con ruido, utilizando distribuciones probabilísticas sobre las asociaciones almacenadas.
\end{itemize}
%
En experimentos previos, la EAM fue evaluada con el conjunto de datos \textit{Fashion MNIST} \cite{zalandoresearchFashionMNIST2022}, compuesto por 70,000 imágenes distribuidas en 10 clases. En este escenario, la memoria fue alimentada con representaciones latentes producidas por un autoencoder convolucional, y demostró capacidad tanto para reconocer como para reconstruir patrones aún en condiciones de ruido o información incompleta. Asimismo, se exploraron fenómenos emergentes como la generación de secuencias de recuerdos (\textit{association chains}), mostrando la capacidad del sistema para transitar entre representaciones almacenadas. Posteriormente, se realizó un primer estudio utilizando el conjunto de datos \emph{Quick, Draw!} de Google, con pequeñas variaciones en el número de clases (entre 10 y 13), con resultados aceptables \cite{gonzalez2024clasificador}.

A pesar de estos resultados prometedores, el marco experimental original presentaba limitaciones relevantes: 
(1) la evaluación se restringió a un conjunto reducido de 10 clases, lo que dificultaba analizar la escalabilidad del modelo en contextos más complejos; 
(2) no se realizaron pruebas sistemáticas sobre la capacidad de la memoria para rechazar patrones de clases no vistas, un aspecto fundamental en el reconocimiento de conjuntos abiertos; y 
(3) el diseño experimental estaba acoplado al número fijo de clases configuradas en las redes neuronales, limitando la flexibilidad para explorar diferentes configuraciones de carga de memoria.

Estas limitaciones motivan el presente trabajo, cuyo objetivo es validar la EAM en un entorno más desafiante mediante la migración al conjunto de datos \textit{Quick, Draw!} \cite{googlecreativelabQuickDrawData2025} y el diseño de un experimento específico para analizar su capacidad de rechazo frente a clases inéditas.



% -------------------- Metodología --------------------
\section{Metodología}

\noindent Con el objetivo de extender la validación del modelo de Memoria Asociativa Entrópica (EAM) y analizar su comportamiento en escenarios más complejos, se diseñó una metodología experimental dividida en tres fases principales. Estas fases permitieron migrar a un nuevo dominio de datos, evaluar el mecanismo de rechazo explícito y dotar al sistema de mayor flexibilidad para futuros experimentos.

\subsection{Migración del conjunto de datos y validación a gran escala}
\noindent El primer paso consistió en reemplazar el conjunto de datos \textit{Fashion MNIST} por \textit{Quick. Draw!} \cite{googlecreativelabQuickDrawData2025}, con más de 300 clases y cientos de miles de ejemplos por categoría. Este proceso requirió:
\begin{itemize}
    \item \textbf{Adaptación del módulo de datos:} Se modificó el script \texttt{dataset.py} para cargar, procesar y balancear dinámicamente clases de \emph{Quick, Draw!}. La lógica se ajustó para manejar un número variable de categorías y garantizar un número equitativo de muestras por clase.
    \item \textbf{Reentrenamiento de las redes neuronales:} Se ajustó el sistema perceptivo, consistente en un autocodificador y un clasificador (definido en \texttt{neural\_net.py}), con base en el trabajo realizado para \cite{moralesMissingCueProblem2025} y se entrenó desde cero el sistema perceptivo  utilizando \emph{Quick, Draw!} como nueva fuente de datos. Este paso generó representaciones latentes (\textit{features}) adecuadas para la memoria.
    \item \textbf{Validación del \emph{pipeline}:} Se ejecutó el flujo completo (entrenamiento del autoencodificador-clasificador, generación de características, almacenamiento en memoria y evaluación de reconocimiento) para verificar la compatibilidad del modelo con el nuevo dominio.
\end{itemize}

\subsection{Diseño e implementación del experimento de rechazo}
\noindent Para analizar la capacidad del sistema de rechazar patrones de clases no vistas, se implementó un segundo experimento con la siguiente lógica:
\begin{itemize}
    \item \textbf{Extensión de la interfaz de comandos:} Se añadió un nuevo argumento en el programa principal \texttt{eam.py} (\texttt{-e 2}) para invocar este modo experimental.
    \item \textbf{Registro parcial en memoria:} Aunque el clasificador fue entrenado con todas las clases seleccionadas, en la EAM se registró únicamente la mitad de ellas.
    \item \textbf{Evaluación con conjunto completo:} En la fase de prueba, el sistema se expuso a todas las clases, incluyendo las no registradas, lo que permitió evaluar explícitamente su respuesta de rechazo.
    \item \textbf{Métrica de aceptación y rechazo:} Se empleó el índice \texttt{no\_response} como medida cuantitativa para evaluar la capacidad del sistema de no asociar patrones pertenecientes a clases no vistas.
\end{itemize}

\subsection{Refactorización para la flexibilidad experimental}
\noindent Con el fin de transformar el sistema en una plataforma experimental más versátil, se llevaron a cabo modificaciones adicionales:
\begin{itemize}
    \item \textbf{Parametrización del número de clases:} El programa \texttt{eam.py} fue modificado para aceptar el número de clases como argumento de ejecución (\texttt{<classes>}), en lugar de estar fijado en el código.
    \item \textbf{Propagación de parámetros:} Este valor fue transmitido al módulo de datos, lo que permitió preparar dinámicamente sólo el subconjunto de clases requerido.
    \item \textbf{Carga dinámica:} El sistema quedó habilitado para realizar experimentos con diferentes cantidades de clases (2, 4, 8, 16, 24 o 32), adaptándose a escenarios controlados de diversa complejidad.
\end{itemize}
%
En conjunto, estas tres fases metodológicas permitieron escalar el modelo hacia un dominio sustancialmente mayor, analizar su capacidad de rechazo ante estímulos inéditos y habilitar una infraestructura más flexible para futuras pruebas experimentales.



% -------------------- Resultados --------------------

\section{Resultados}

\subsection{Resultados cuantitativos por número de clases}
\indent En esta sección se presenta el desempeño del autoencodificador-clasificador y la memoria asociativa entrópica al variar el número de clases. De las 345 clases que contiene el conjunto de datos \emph{Quick, Draw!} se seleccionaron 64 en total, se revolvieron aleatoriamente y del conjunto resultante se fueron tomando las primeras 2, 4, 8, 16, 24 y 32 clases. El conjunto de datos resultante en cada caso se dividió en tres: el corpus de entrenamiento del autocodificador-clasificador, el corpus de llenado de la memoria asociativa entrópica y el corpus de prueba de ambos. Por cuestiones de tiempo y limitaciones en la cantidad de memoria del servidor, no se hicieron pruebas con más clases y solamente se ejecutó una sola validación por número de clases, en vez de la validación cruzada. Sin embargo, la coherencia de los resultados sugiere que estos no están lejos de lo que se obtendría con una validación cruzada.

Como en \cite{pinedaImageryEntropicAssociative2023} y \cite{moralesMissingCueProblem2025}, las redes neuronales que implementan el autocodificador y el clasificador fueron entrenadas conjuntamente. El Cuadro~\ref{tab:autoencoder-classifier-performance} presenta su desempeño en el conjunto de prueba para las distintas cantidades de clases tomadas del conjunto de datos. Como se puede observar, el desempeño del clasificador tiende a bajar conforme aumenta el número de clases, pero se mantuvo arriba del 91\% de exactitud. El desempeño del autocodificador se mantiene un poco más estable, con una diferencia menor al 3\% entre todos los casos.

\begin{table}[htbp]
	\centering
	\caption{Desempeño del autocodificador (raíz cuadrada del error promedio) y el clasificador (exactitud) para distintas cantidades de clases.}
	\begin{tabular}{@{}ccc@{}}\toprule
		No. de clases & Exactitud &  Error \\
		\midrule
		2 & 0.976 & 0.218 \\
		4 & 0.950 & 0.215 \\
		8 & 0.921 & 0.204 \\
		16 & 0.914 & 0.218 \\
		24	& 0.917 & 0.228 \\
		32 & 0.917 & 0.229 \\
		\bottomrule
	\end{tabular}
	\label{tab:autoencoder-classifier-performance}
\end{table}

\subsection{Resultados del experimento de reconocimiento (todas las clases registradas en memoria)}
\noindent En este experimento la memoria almacenó todas las clases disponibles, con las que las redes neuronales fueron entrenadas y evaluadas. Las figuras de la \ref{fig:precision_2} a la \ref{fig:precision_32} muestran los desempeños correspondientes de la memoria asociativa entrópica usando las métricas de precisión y exactitud. En todos los casos se mantuvo el mismo número de columnas en la memoria (256) y se varió el número de renglones en potencias de dos, desde 2 hasta 1024. De manera general, se puede observar que los desempeños con 4 o más renglones fueron muy similares entre sí y similares a los obtenidos por el clasificador.

% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 2 clases.}
    \label{fig:precision_2}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 4 clases.}
    \label{fig:precision_4}
\end{figure}

% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 8 clases.}
    \label{fig:precision_8}
\end{figure}

% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 16 clases.}
    \label{fig:precision_16}
\end{figure}

% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 24 clases.}
    \label{fig:precision_24}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/graph_prse_MEAN-english.pdf}
    \caption{Precisión y exactitud de la memoria asociativa con 32 clases.}
    \label{fig:precision_32}
\end{figure}


% --------------------
\noindent Para observar el desempeño de la memoria conforme se va llenando de recuerdos, para cada cantidad de clases se selecciono un número de renglones con buen desempeño y se observó el comportamiento de la precisión y la exactitud de la memoria conforme se fue llenando en porcentajes que también variaron en potencias de dos. Las figuras de la \ref{fig:recall_exp1_2_004} a la \ref{fig:recall_exp1_32_016} presentan los resultados obtenidos. En general, se puede decir que el desempeño de la memoria se mantiene cuando se llena con al menos el 8\% del corpus de llenado.


% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/recall-exp_001-sze_004-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 2 clases y memoria con 4 renglones.}
    \label{fig:recall_exp1_2_004}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 4 clases y memoria con 32 renglones.}
    \label{fig:recall_exp1_4_032}
\end{figure}


% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 8 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_8_016}
\end{figure}


% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 16 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_16_016}
\end{figure}


% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/recall-exp_001-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 24 clases y memoria con 32 renglones.}
    \label{fig:recall_exp1_24_032}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/recall-exp_001-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de reconocimiento con 32 clases y memoria con 16 renglones.}
    \label{fig:recall_exp1_32_016}
\end{figure}


% --------------------


\subsection{Resultados del experimento de rechazo de clases no registradas}
\noindent En este experimento solamente se registró en la memoria la primera mitad de las clases, pero se evaluó contra el conjunto completo. Para cada cantidad de clases se seleccionó el mismo número de renglones para la memoria que en el experimento anterior (figuras de la \ref{fig:recall_exp1_2_004} a la \ref{fig:recall_exp1_32_016}) y se observó el desempeño de la memoria conforme se fue llenando. Las figuras de la \ref{fig:recall_exp2_2_004} a la \ref{fig:recall_exp2_32_016} presentan las gráficas de precisión y exactitud correspondientes. Se puede observar como el desempeño de la memoria comienza muy bien con dos clases y poca información registrada en ella, y va disminuyendo conforme se incrementan tanto el número de clases como la cantidad de elementos del corpus de llenado que se registra en la memoria.

% -- 2 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_02/recall-exp_002-sze_004-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 2 clases y memoria con 4 renglones.}
    \label{fig:recall_exp2_2_004}
\end{figure}

% -- 4 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_04/recall-exp_002-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 4 clases y memoria con 32 renglones.}
    \label{fig:recall_exp2_4_032}
\end{figure}


% -- 8 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_08/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 8 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_8_016}
\end{figure}


% -- 16 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_16/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 16 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_16_016}
\end{figure}


% -- 24 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_24/recall-exp_002-sze_032-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 24 clases y memoria con 32 renglones.}
    \label{fig:recall_exp2_24_032}
\end{figure}

% -- 32 Clases
\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\textwidth]{Graficas/runs_32/recall-exp_002-sze_016-graph_prse_MEAN-english.pdf}
    \caption{Resultados del experimento de rechazo con 32 clases y memoria con 16 renglones.}
    \label{fig:recall_exp2_32_016}
\end{figure}



% -------------------- Discución --------------------
\section{Discussion}
\noindent The experimental results allow for several relevant observations about the behavior of the Entropic Associative Memory (EAM) in more complex scenarios.

Firstly, by progressively increasing the number of classes, a general trend of decreasing precision and recall metrics was observed. This behavior is expected, as the domain complexity and pattern variability grow with the number of categories. Nevertheless, the EAM maintained stable performance in low and medium-complexity configurations, which confirms its ability to scale beyond the reduced Fashion MNIST domain.

Secondly, the rejection experiments showed that the memory was capable of identifying patterns corresponding to classes registered within it and rejecting instances of unregistered classes. This result provides empirical validation for the hypothesis that EAM can operate in open-set recognition scenarios, differentiating between familiar and unfamiliar stimuli. However, cases of false acceptances for instances of unregistered classes were also detected as the number of classes, or the percentage of the corpus filled in the memory, increased. This suggests a need to adjust threshold parameters ($\iota$ and $\kappa$ \cite{pinedaImageryEntropicAssociative2023,moralesMissingCueProblem2025}), try other row numbers, or explore complementary discrimination mechanisms.

Finally, the comparison with the baseline classifier highlights the role of the memory in the complete system. While the classifier provides useful latent representations, it is the EAM that confers the probabilistic rejection and retrieval capability, providing added value compared to purely discriminative architectures.

Collectively, these findings demonstrate that EAM can not only adapt to more complex domains but also offers an effective mechanism for handling novel information. At the same time, they highlight future challenges related to optimizing its parameters and evaluating it in even larger and more heterogeneous domains.


% -------------------- Conclusiones --------------------
\section{Conclusions}

\noindent This work extended the experimental framework of the Entropic Associative Memory (EAM) to evaluate its performance in more complex scenarios and analyze its rejection capacity for unregistered classes. The main contributions can be summarized as follows:

\begin{itemize}
    \item \textbf{Large-scale validation:} We migrated from a reduced domain of ten classes in Fashion MNIST to a wider and more diverse domain using \emph{Quick, Draw!}, with results that confirm the model's ability to scale in contexts with much more classes and greater variability in patterns.
    
    \item \textbf{Rejection capacity:} A new experiment was designed and implemented, empirically showing how the EAM is capable of issuing a rejection to stimuli corresponding to unseen classes, validating its usefulness in open-set recognition problems.
    
    \item \textbf{Experimental flexibility:} The system was refactored to accept a variable number of classes and different memory sizes, which enables a more versatile environment for exploring configurations and comparative analysis.
\end{itemize}

\noindent The findings demonstrate that the EAM is an explainable and robust model, capable of combining distributed storage with probabilistic retrieval and rejection mechanisms. These results reinforce its potential as an alternative paradigm within artificial intelligence, particularly in tasks where the ability to handle novel information is critical.

For future work, it is proposed to extend the experiments to even larger and more heterogeneous domains, to optimize the threshold parameters associated with rejection, and investigate the integration of EAM with more advanced deep learning architectures to strengthen both its accuracy and generalization capacity.


% -------------------- Referencias --------------------
\bibliographystyle{IEEEtran}
\bibliography{articulo}
\end{document}
